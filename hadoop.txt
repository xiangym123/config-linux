hadoop-env.sh
环境变量

core-site.xml
<property>
        <name>fs.defaultFS</name>  //文件系统  默认为fs.defaultFS
        <value>hdfs://localhost:9000</value>  //资源定位   hdfs 协议   nameDate  地址localhost:9000
    </property>

<property>
        <name>hadoop.tmp.dir</name>  
        <value>/usr/local/hadoop/hadoop-2.9.2/data</value>  
    </property>//nameDate    保存数据的地方

hdfs-site.xml:
<configuration>
    <property>
        <name>dfs.replication</name>     //副本数  一般为3
        <value>1</value>
    </property>
</configuration>




mapred-site.xml:
mv mapred-site.xml.template  mapred-site.xml    //重命名
<property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>


yarn-site.xml
<property>
        <name>yarn.nodemanager.hostname</name>
        <value>localhost</value>
 </property>
<property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
 </property>

2、关防火墙
sudo service status
service iptables   start


将  hadoop 添加到环境变量中
export JAVA_HOME=/usr/local/jdk/jdk1.7.0_79
export HADOOP_HOME=/usr/local/hadoop/hadoop-2.9.2
export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin



格式化数据
hadoop namenode -format


start-dfs.sh
[root@iZ2zee37lo37bvcc4y8unrZ sbin]# start-dfs.sh 
Starting namenodes on [localhost]
root@localhost's password: 
localhost: starting namenode, logging to /usr/local/hadoop/hadoop-2.9.2/logs/hadoop-root-namenode-iZ2zee37lo37bvcc4y8unrZ.out

localhost: starting datanode, logging to /usr/local/hadoop/hadoop-2.9.2/logs/hadoop-root-datanode-iZ2zee37lo37bvcc4y8unrZ.out
Starting secondary namenodes [0.0.0.0]

0.0.0.0: starting secondarynamenode, logging to /usr/local/hadoop/hadoop-2.9.2/logs/hadoop-root-secondarynamenode-iZ2zee37lo37bvcc4y8unrZ.out
[root@iZ2zee37lo37bvcc4y8unrZ sbin]# 


看进程 jps





start-yarn.sh 
starting yarn daemons

starting resourcemanager, logging to /usr/local/hadoop/hadoop-2.9.2/logs/yarn-root-resourcemanager-iZ2zee37lo37bvcc4y8unrZ.out

localhost: starting nodemanager, logging to /usr/local/hadoop/hadoop-2.9.2/logs/yarn-root-nodemanager-iZ2zee37lo37bvcc4y8unrZ.out










hadoop fs -put hadoop-2.9.2.tar.gz hdfs:localhost:9000/










chomd 600 authorized_keys  修改权限


cat id_rsa.pub  >>authorized_keys  追加内容s

hadoop fs -mkdir /srcdata

hadoop fs -put hello /wc/srcdata

hadoop dfsadmin -safemode leave   //内存不足	


rm -rf cb   //强制 递归删除

 reboot 


ssh-keygen -t rsa


 netstat -nap | grep 9000
